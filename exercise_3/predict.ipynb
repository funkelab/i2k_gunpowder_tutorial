{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZarrSource[../data/mouse.n5], providing: \n",
      "\tRAW: ROI: [225:275, 0:4940, 0:2048, 0:2169] (50, 4940, 2048, 2169), voxel size: (1, 5, 1, 1), interpolatable: True, non-spatial: False, dtype: uint16, placeholder: False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gunpowder.nodes.scan:scanning over 1024 chunks\n",
      "INFO:gunpowder.torch.nodes.predict:Predicting on gpu\n",
      "  0%|          | 0/1024 [00:00<?, ?it/s]INFO:gunpowder.nodes.scan:allocating array of shape (1, 32, 1000, 1000) for PREDICTION\n",
      "100%|██████████| 1024/1024 [04:44<00:00,  3.60it/s]\n",
      "INFO:gunpowder.producer_pool:terminating workers...\n",
      "INFO:gunpowder.producer_pool:joining workers...\n",
      "INFO:gunpowder.producer_pool:done\n",
      "INFO:gunpowder.producer_pool:terminating workers...\n",
      "INFO:gunpowder.producer_pool:joining workers...\n",
      "INFO:gunpowder.producer_pool:done\n"
     ]
    }
   ],
   "source": [
    "from funlib.learn.torch.models import UNet, ConvPass\n",
    "import gunpowder as gp\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import zarr\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "checkpoint = 100000\n",
    "predict_roi = gp.Roi((250, 2000, 500, 500), (1, 160, 1000, 1000))\n",
    "\n",
    "raw = gp.ArrayKey(\"RAW\")\n",
    "prediction = gp.ArrayKey(\"PREDICTION\")\n",
    "\n",
    "input_shape = (7, 64, 124, 124)\n",
    "output_shape = (1, 32, 32, 32)\n",
    "\n",
    "unet = UNet(\n",
    "    in_channels=7,\n",
    "    num_fmaps=12,\n",
    "    fmap_inc_factor=5,\n",
    "    downsample_factors=[\n",
    "        (1, 2, 2),\n",
    "        (1, 2, 2),\n",
    "        (2, 2, 2)],\n",
    "    constant_upsample=True,\n",
    "    padding='valid')\n",
    "model = torch.nn.Sequential(\n",
    "    unet,\n",
    "    ConvPass(12, 1, [(1, 1, 1)], activation=None),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "raw_source = gp.ZarrSource(\n",
    "    '../data/mouse.n5',\n",
    "    {raw: 'volumes/raw'},\n",
    "    {raw: gp.ArraySpec(interpolatable=True)}\n",
    ")\n",
    "\n",
    "with gp.build(raw_source):\n",
    "    print(raw_source)\n",
    "    voxel_size = raw_source.spec[raw].voxel_size\n",
    "\n",
    "input_size = voxel_size*input_shape\n",
    "output_size = voxel_size*output_shape\n",
    "\n",
    "scan_request = gp.BatchRequest()\n",
    "scan_request.add(raw, input_size)\n",
    "scan_request.add(prediction, output_size)\n",
    "\n",
    "pipeline = (\n",
    "    raw_source +\n",
    "    gp.Pad(raw, None) +\n",
    "    gp.Normalize(raw, dtype=np.float32) +\n",
    "    gp.Stack(1) +\n",
    "    gp.torch.Predict(\n",
    "        model,\n",
    "        inputs={\n",
    "            'input': raw\n",
    "        },\n",
    "        outputs={\n",
    "            0: prediction\n",
    "        },\n",
    "        checkpoint=f'model_checkpoint_{checkpoint}',\n",
    "        spawn_subprocess=True\n",
    "    ) +\n",
    "    gp.Squeeze([raw, prediction]) +\n",
    "    gp.ZarrWrite(\n",
    "        output_filename=f'prediction_{checkpoint}.zarr',\n",
    "        dataset_names={\n",
    "            prediction: 'prediction'\n",
    "        }\n",
    "    ) +\n",
    "    gp.Scan(scan_request, num_workers=8)\n",
    ")\n",
    "\n",
    "total_request = gp.BatchRequest()\n",
    "total_request[prediction] = predict_roi\n",
    "\n",
    "# prepare the output dataset\n",
    "f = zarr.open(f'prediction_{checkpoint}.zarr', 'w')\n",
    "ds = f.create_dataset(\n",
    "    'prediction',\n",
    "    shape=predict_roi.get_shape()/voxel_size,\n",
    "    chunks=output_shape, dtype=np.float32)\n",
    "ds.attrs['offset'] = predict_roi.get_begin()\n",
    "ds.attrs['resolution'] = voxel_size\n",
    "\n",
    "with gp.build(pipeline):\n",
    "    batch = pipeline.request_batch(total_request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
